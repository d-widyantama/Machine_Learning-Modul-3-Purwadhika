{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Outline for Supervised Learning:\n",
    "\n",
    "1. Data Load\n",
    "2. Data Cleaning\n",
    "3. Split Data\n",
    "4. Feature Engineering\n",
    "5. Model Benchmarking \n",
    "    - Cross Validation\n",
    "    - Model Selection\n",
    "6. Model Evaluation\n",
    "    - Hyperparameter Tuning\n",
    "    - Feedback to Cleaning or Feature Engineering\n",
    "7. Model Deployment (Final Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Main goal for hyperparameter tuning is to find the best set of hyperparameters for our model. (e.g Max Depth for DT, N neighbours in KNN, etc.)\n",
    "\n",
    "- Hyperparameters are the knobs that we can turn to improve our model\n",
    "- Hyperparameters are set before training the model\n",
    "- Hyperparameters are not learned by the model, but are set by the data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKlearn Tools for Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Grid Search\n",
    "    - Exhaustive search over **each** specified parameter values for an estimator.\n",
    "    - **Pros**: Exhaustive search over all parameter combinations\n",
    "    - **Cons**: Computationally expensive\n",
    "2. Random Search\n",
    "    - Randomized search on hyper parameters, we define a range of hyperparameters and randomly sample within the range.\n",
    "    - **Pros**: Randomized search over specified parameter values\n",
    "    - **Cons**: Not as exhaustive as Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If not chosen carefully, hyperparameter tuning can be computationally expensive and resulted in overfitting\n",
    "- Hyperparameter tuning is not a substitute for feature engineering\n",
    "- Hyperparameter tuning is not a substitute for model selection, better to tune a model that has been selected from cross validation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
